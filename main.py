import os
import json
import asyncio
import logging
from typing import Dict, List
from pymongo import MongoClient
from dotenv import load_dotenv
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch
import aiohttp
import numpy as np
from llama_cpp import Llama

# ä¸¥æ ¼éµå¾ªå®˜æ–¹MCPç¤ºä¾‹çš„å¯¼å…¥æ–¹å¼
from mcp.server.fastmcp import FastMCP

# -------------------------- åŸºç¡€é…ç½® --------------------------
# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    encoding='utf-8'
)
logger = logging.getLogger("bio-invasion-mcp")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
ENV = os.getenv("MCP_ENV", "development")

# -------------------------- å…¨å±€èµ„æºåˆå§‹åŒ– --------------------------
# 1. å¼‚æ­¥HTTPä¼šè¯ï¼ˆæ‡’åŠ è½½ï¼‰
aiohttp_session = None

# 2. MongoDBè¿æ¥
def init_mongo():
    # ä½¿ç”¨æ–°çš„ç¯å¢ƒå˜é‡å‘½åçº¦å®š
    mongo_uri = os.getenv("MONGO_URI", "mongodb://localhost:27017/")
    db_name = os.getenv("MONGO_DB_NAME", "test_db")
    col_name = os.getenv("MONGO_COLLECTION", "test_collection")
    try:
        client = MongoClient(mongo_uri, serverSelectionTimeoutMS=5000)
        client.admin.command("ping")  # éªŒè¯è¿æ¥
        db = client[db_name]
        col = db[col_name]
        logger.info(f"âœ… MongoDBè¿æ¥æˆåŠŸï¼š{db_name}.{col_name}")
        return client, col
    except Exception as e:
        logger.error(f"âŒ MongoDBåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡å™¨åœ¨æ²¡æœ‰MongoDBçš„æƒ…å†µä¸‹å¯åŠ¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        return None, None

mongo_client, mongo_col = init_mongo()

# 3. åµŒå…¥æ¨¡å‹ï¼ˆæ‡’åŠ è½½ï¼‰
embedding_llm = None
reranker_model = None
reranker_tokenizer = None

def init_embedding_model():
    """åˆå§‹åŒ–æœ¬åœ°åµŒå…¥æ¨¡å‹ï¼ˆä½¿ç”¨llama-cpp-pythonåŠ è½½GGUFæ–‡ä»¶ï¼‰"""
    global embedding_llm
    model_path = os.getenv("LOCAL_EMBEDDING_MODEL_PATH", "C:\\Users\\admin\\.ollama\\models\\blobs\\sha256-14037f526fecc2f9e23bb9ef544bc733bcef605feb110fe724349df5a4bad3ee")
    
    try:
        # ä½¿ç”¨llama-cpp-pythonåŠ è½½GGUFæ¨¡å‹æ–‡ä»¶
        embedding_llm = Llama(
            model_path=model_path,
            embedding=True,  # å¯ç”¨åµŒå…¥åŠŸèƒ½
            n_ctx=4096,      # ä¸Šä¸‹æ–‡é•¿åº¦
            n_threads=4,     # çº¿ç¨‹æ•°
            verbose=False    # ä¸è¾“å‡ºè¯¦ç»†æ—¥å¿—
        )
        logger.info(f"âœ… æœ¬åœ°åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_path}")
    except Exception as e:
        logger.warning(f"âš ï¸  æœ¬åœ°åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")

def init_reranker():
    """åˆå§‹åŒ–é‡æ’åºæ¨¡å‹"""
    global reranker_model, reranker_tokenizer
    model_name = os.getenv("RERANKER_MODEL", "BAAI/bge-reranker-large")
    try:
        reranker_tokenizer = AutoTokenizer.from_pretrained(model_name)
        reranker_model = AutoModelForSequenceClassification.from_pretrained(model_name)
        reranker_model.eval()
        logger.info(f"âœ… é‡æ’åºæ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_name}")
    except Exception as e:
        logger.warning(f"âš ï¸  é‡æ’åºæ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}ï¼ˆå°†ç”¨åŸç”Ÿå‘é‡æ’åºï¼‰")

# åˆå§‹åŒ–æ¨¡å‹
init_embedding_model()
init_reranker()

# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° --------------------------
async def get_embedding(text: str) -> List[float]:
    """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡ï¼ˆåŸºäºæœ¬åœ°GGUFæ¨¡å‹æ–‡ä»¶ï¼‰"""
    try:
        if embedding_llm is None:
            raise RuntimeError("æœ¬åœ°åµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–")
        
        # ä½¿ç”¨llama-cpp-pythonç”ŸæˆåµŒå…¥å‘é‡
        embedding_result = embedding_llm.create_embedding(text)
        embedding_vector = embedding_result["data"][0]["embedding"]
        
        # L2å½’ä¸€åŒ–
        embedding_vector = np.array(embedding_vector)
        embedding_vector = embedding_vector / np.linalg.norm(embedding_vector)
        embedding_vector = embedding_vector.tolist()
        
        logger.info(f"âœ… æœ¬åœ°åµŒå…¥æ¨¡å‹ç”Ÿæˆå‘é‡æˆåŠŸï¼Œç»´åº¦ï¼š{len(embedding_vector)}")
        return embedding_vector
        
    except Exception as e:
        logger.error(f"âŒ æœ¬åœ°åµŒå…¥æ¨¡å‹ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        raise RuntimeError(f"æœ¬åœ°åµŒå…¥æ¨¡å‹ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")

async def enhance_with_deepseek(query: str, results: List[Dict]) -> List[Dict]:
    """ç”¨DeepSeekå¢å¼ºç»“æœï¼ˆæ·»åŠ ä¸“ä¸šè§£é‡Šï¼‰"""
    global aiohttp_session
    # æ‡’åŠ è½½aiohttpä¼šè¯
    if aiohttp_session is None:
        aiohttp_session = aiohttp.ClientSession()
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    api_url = os.getenv("DEEPSEEK_API_URL", "https://api.deepseek.com/v1/chat/completions")
    if not api_key:
        logger.warning("âš ï¸  æœªé…ç½®DeepSeek API Keyï¼Œè·³è¿‡å¢å¼º")
        return results
    
    try:
        prompt = f"""ä¸ºç”Ÿç‰©å…¥ä¾µæŸ¥è¯¢ã€Œ{query}ã€çš„ç»“æœï¼Œæ¯ä¸ªæ¡ç›®æ–°å¢1å¥ä¸“ä¸šè§£é‡Šï¼ˆkeyä¸º"enhanced_info"ï¼‰ï¼Œä»…è¿”å›JSONï¼š
{json.dumps(results, ensure_ascii=False)}"""
        async with aiohttp_session.post(
            api_url,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            },
            json={
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.2,
                "max_tokens": 2048
            },
            timeout=15
        ) as resp:
            if resp.status != 200:
                raise RuntimeError(f"DeepSeek API status: {resp.status}")
            data = await resp.json()
            return json.loads(data["choices"][0]["message"]["content"])
    except Exception as e:
        logger.error(f"âŒ DeepSeekå¢å¼ºå¤±è´¥ï¼š{str(e)}")
        return results

# -------------------------- MCPæœåŠ¡å™¨åˆå§‹åŒ– --------------------------
# åˆå§‹åŒ–MCPæœåŠ¡ï¼ˆå®Œå…¨éµå¾ªå®˜æ–¹ç¤ºä¾‹ï¼‰
mcp = FastMCP("bio-invasion-mongo-server")

@mcp.tool()
async def text_to_vector(text: str) -> Dict:
    """å°†ç”Ÿç‰©å…¥ä¾µç›¸å…³æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥å‘é‡
    
    Args:
        text (str): éœ€è½¬æ¢çš„æ–‡æœ¬ï¼ˆå»ºè®®â‰¤512å­—ç¬¦ï¼Œå†…å®¹ä¸ºç”Ÿç‰©å…¥ä¾µæè¿°ï¼‰
     
    Returns:
        Dict: åŒ…å«å‘é‡ã€ç»´åº¦ã€æ¨¡å‹ä¿¡æ¯çš„ç»“æœ
    """
    try:
        if not text.strip():
            return {"status": "error", "msg": "textä¸èƒ½ä¸ºç©º"}
        
        vector = await get_embedding(text.strip())
        return {
            "status": "success",
            "data": {
                "text": text.strip(),
                "vector": vector,
                "dimension": len(vector),
                "model": os.getenv("EMBEDDING_MODEL", "dengcao/Qwen3-Embedding-8B:Q5_K_M")
            }
        }
    except Exception as e:
        return {"status": "error", "msg": str(e)}

@mcp.tool()
async def create_vector_index(dimension: int = 768) -> Dict:
    """ä¸ºMongoDBé›†åˆåˆ›å»ºå‘é‡ç´¢å¼•
    
    Args:
        dimension (int): å‘é‡ç»´åº¦ï¼Œé»˜è®¤ä¸º768
        
    Returns:
        Dict: ç´¢å¼•åˆ›å»ºç»“æœ
    """
    try:
        if mongo_col is None:
            return {"status": "error", "msg": "MongoDBè¿æ¥æœªåˆå§‹åŒ–"}
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å‘é‡ç´¢å¼•
        existing_indexes = mongo_col.index_information()
        if "vector_index" in existing_indexes:
            return {"status": "success", "msg": "å‘é‡ç´¢å¼•å·²å­˜åœ¨"}
        
        # åˆ›å»ºå‘é‡ç´¢å¼• - ä½¿ç”¨æ­£ç¡®çš„MongoDBè¯­æ³•
        index_definition = {
            "name": "vector_index",
            "key": {"embedding": "vector"},
            "vectorOptions": {
                "dimension": dimension,
                "similarity": "cosine"
            }
        }
        
        # ä½¿ç”¨create_indexåˆ›å»ºå‘é‡ç´¢å¼•
        mongo_col.create_index([("embedding", "vector")], name="vector_index")
        logger.info(f"âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸï¼Œç»´åº¦ï¼š{dimension}")
        
        return {
            "status": "success", 
            "msg": f"å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸï¼Œç»´åº¦ï¼š{dimension}",
            "index_name": "vector_index"
        }
        
    except Exception as e:
        logger.error(f"âŒ å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼š{str(e)}")
        return {"status": "error", "msg": f"ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼š{str(e)}"}

@mcp.tool()
async def check_database_content() -> Dict:
    """æ£€æŸ¥æ•°æ®åº“å†…å®¹å’Œç»“æ„"""
    try:
        if mongo_col is None:
            return {"status": "error", "msg": "MongoDBè¿æ¥æœªåˆå§‹åŒ–"}
        
        # æ£€æŸ¥é›†åˆä¸­çš„æ–‡æ¡£æ•°é‡
        total_docs = mongo_col.count_documents({})
        
        # æ£€æŸ¥åŒ…å«åµŒå…¥å‘é‡çš„æ–‡æ¡£æ•°é‡
        docs_with_embedding = mongo_col.count_documents({"embedding": {"$exists": True}})
        
        # æ£€æŸ¥ç´¢å¼•ä¿¡æ¯
        indexes = mongo_col.index_information()
        
        # è·å–ä¸€äº›ç¤ºä¾‹æ–‡æ¡£ç»“æ„
        sample_docs = list(mongo_col.find().limit(3))
        
        return {
            "status": "success",
            "database_info": {
                "total_documents": total_docs,
                "documents_with_embedding": docs_with_embedding,
                "indexes": list(indexes.keys()),
                "sample_document_structure": [str(doc.get("_id")) for doc in sample_docs] if sample_docs else []
            }
        }
        
    except Exception as e:
        return {"status": "error", "msg": f"æ•°æ®åº“æ£€æŸ¥å¤±è´¥ï¼š{str(e)}"}

@mcp.tool()
async def natural_language_query(
    user_input: str,
    limit: int = 5,
    use_reranker: bool = True,
    enhance_output: bool = False
) -> Dict:
    """è‡ªç„¶è¯­è¨€æŸ¥è¯¢MongoDBæ•°æ®åº“ - å®Œæ•´æµç¨‹
    
    å®Œæ•´æµç¨‹ï¼šç”¨æˆ·è¾“å…¥æ–‡æœ¬ â†’ åµŒå…¥æ¨¡å‹å‘é‡åŒ– â†’ å‘é‡æŸ¥è¯¢ â†’ é‡æ’åº â†’ æºæ–‡æœ¬æŸ¥æ‰¾ â†’ ä¼˜åŒ–è¾“å‡º
    
    Args:
        user_input (str): ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ–‡æœ¬
        limit (int): è¿”å›ç»“æœæ•°é‡ï¼ˆ1-20ï¼Œé»˜è®¤5ï¼‰
        use_reranker (bool): æ˜¯å¦ä½¿ç”¨é‡æ’åºæ¨¡å‹ä¼˜åŒ–ç»“æœï¼ˆé»˜è®¤Trueï¼‰
        enhance_output (bool): æ˜¯å¦ä½¿ç”¨AIæ¨¡å‹ä¼˜åŒ–è¾“å‡ºå†…å®¹ï¼ˆé»˜è®¤Falseï¼‰
    
    Returns:
        Dict: åŒ…å«å®Œæ•´æŸ¥è¯¢æµç¨‹ç»“æœçš„å­—å…¸
    """
    try:
        logger.info(f"ğŸ” å¼€å§‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢æµç¨‹ï¼š'{user_input}'")
        
        # 1. ç”¨æˆ·è¾“å…¥æ–‡æœ¬å¤„ç†
        user_input = user_input.strip()
        if not user_input:
            return {"status": "error", "msg": "ç”¨æˆ·è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º"}
        limit = max(1, min(limit, 20))  # é™åˆ¶1-20èŒƒå›´

        # 2. ä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        logger.info("ğŸ“Š æ­¥éª¤1ï¼šä½¿ç”¨åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡")
        query_vector = await get_embedding(user_input)
        logger.info(f"âœ… å‘é‡è½¬æ¢å®Œæˆï¼Œç»´åº¦ï¼š{len(query_vector)}")

        # 3. åœ¨æ•°æ®åº“ä¸­è¿›è¡Œå‘é‡æŸ¥è¯¢
        logger.info("ğŸ” æ­¥éª¤2ï¼šåœ¨MongoDBä¸­è¿›è¡Œå‘é‡æŸ¥è¯¢")
        if mongo_col is None:
            return {"status": "error", "msg": "MongoDBè¿æ¥æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“é…ç½®"}
        
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‘é‡ç´¢å¼•
            if "vector_index" in mongo_col.index_information():
                # ä½¿ç”¨MongoDBçš„å‘é‡æœç´¢åŠŸèƒ½
                pipeline = [
                    {
                        "$vectorSearch": {
                            "index": "vector_index",
                            "queryVector": query_vector,
                            "path": "embedding",
                            "limit": limit * 3,  # å–3å€ç”¨äºåç»­é‡æ’åº
                            "numCandidates": 100
                        }
                    },
                    {
                        "$project": {
                            "embedding": 0,  # ä¸è¿”å›å‘é‡æ•°æ®
                            "vector_score": {"$meta": "vectorSearchScore"},
                            "content": 1,
                            "metadata": 1,
                            "_id": 1,
                            "source": 1
                        }
                    }
                ]
                vector_results = list(mongo_col.aggregate(pipeline))
                logger.info(f"âœ… å‘é‡æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(vector_results)} ä¸ªå€™é€‰ç»“æœ")
            else:
                logger.warning("âš ï¸  æ— vector_indexï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—")
                # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œå‘é‡æŸ¥è¯¢
                vector_results = []
                for doc in mongo_col.find({}):
                    if 'embedding' in doc:
                        doc_vector = np.array(doc['embedding'])
                        similarity = np.dot(query_vector, doc_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(doc_vector))
                        # åªä¿ç•™ç›¸ä¼¼åº¦å¤§äº0.1çš„ç»“æœ
                        if similarity > 0.1:
                            vector_results.append({
                                **doc,
                                "vector_score": float(similarity),
                                "_id": doc.get("_id")
                            })
                
                # æŒ‰ç›¸ä¼¼åº¦æ’åº
                vector_results.sort(key=lambda x: x.get("vector_score", 0), reverse=True)
                vector_results = vector_results[:limit * 3]
                logger.info(f"âœ… ä½™å¼¦ç›¸ä¼¼åº¦æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(vector_results)} ä¸ªå€™é€‰ç»“æœ")
        except Exception as e:
            logger.error(f"âŒ MongoDBå‘é‡æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")
            return {"status": "error", "msg": f"MongoDBæŸ¥è¯¢å¤±è´¥: {str(e)}"}

        # 4. å¯¹æŸ¥è¯¢åˆ°çš„å‘é‡è¿›è¡Œé‡æ’åº
        logger.info("ğŸ“ˆ æ­¥éª¤3ï¼šå¯¹æŸ¥è¯¢ç»“æœè¿›è¡Œé‡æ’åº")
        if use_reranker and reranker_model and len(vector_results) > 1:
            # æå–æ–‡æ¡£å†…å®¹ç”¨äºé‡æ’åº
            doc_contents = []
            for doc in vector_results:
                content = doc.get("content", "")
                if isinstance(content, dict):
                    content = json.dumps(content, ensure_ascii=False)
                doc_contents.append(str(content))
            
            # åˆ›å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹
            pairs = [[user_input, content] for content in doc_contents]
            
            # ä½¿ç”¨é‡æ’åºæ¨¡å‹è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            with torch.no_grad():
                inputs = reranker_tokenizer(
                    pairs, 
                    padding=True, 
                    truncation=True, 
                    return_tensors="pt", 
                    max_length=512
                )
                rerank_scores = reranker_model(**inputs).logits.squeeze().tolist()
            
            # ç»‘å®šé‡æ’åºåˆ†æ•°å¹¶æ’åº
            for idx, score in enumerate(rerank_scores):
                vector_results[idx]["rerank_score"] = float(score)
            
            # æŒ‰é‡æ’åºåˆ†æ•°é™åºæ’åˆ—
            vector_results.sort(key=lambda x: x.get("rerank_score", 0), reverse=True)
            logger.info(f"âœ… é‡æ’åºå®Œæˆï¼Œæœ€é«˜åˆ†ï¼š{max(rerank_scores):.4f}")
        
        # å–å‰limitä¸ªç»“æœ
        final_results = vector_results[:limit]

        # 5. æ‰¾åˆ°æºæ–‡æœ¬å¹¶è¿›è¡Œä¼˜åŒ–è¾“å‡º
        logger.info("ğŸ“ æ­¥éª¤4ï¼šæºæ–‡æœ¬æŸ¥æ‰¾å’Œä¼˜åŒ–è¾“å‡º")
        optimized_results = []
        
        for result in final_results:
            # æå–æºæ–‡æœ¬å†…å®¹
            source_content = result.get("content", "")
            metadata = result.get("metadata", {})
            
            # æ„å»ºä¼˜åŒ–åçš„ç»“æœ
            optimized_result = {
                "source_id": str(result.get("_id", "")),
                "source_content": source_content,
                "metadata": metadata,
                "vector_score": result.get("vector_score", 0),
                "rerank_score": result.get("rerank_score", 0),
                "relevance_score": calculate_relevance_score(result)
            }
            
            # å¦‚æœå¯ç”¨è¾“å‡ºå¢å¼ºï¼Œä½¿ç”¨AIæ¨¡å‹ä¼˜åŒ–å†…å®¹
            if enhance_output:
                optimized_result = await enhance_result_content(user_input, optimized_result)
            
            optimized_results.append(optimized_result)
        
        # 6. è¿”å›ä¼˜åŒ–åçš„å®Œæ•´ç»“æœ
        logger.info(f"âœ… æŸ¥è¯¢æµç¨‹å®Œæˆï¼Œè¿”å› {len(optimized_results)} ä¸ªä¼˜åŒ–ç»“æœ")
        return {
            "status": "success",
            "query_process": {
                "user_input": user_input,
                "vector_dimension": len(query_vector),
                "candidate_count": len(vector_results),
                "final_count": len(optimized_results)
            },
            "results": optimized_results,
            "summary": generate_query_summary(user_input, optimized_results)
        }
        
    except Exception as e:
        logger.error(f"âŒ è‡ªç„¶è¯­è¨€æŸ¥è¯¢æµç¨‹å¤±è´¥ï¼š{str(e)}")
        return {"status": "error", "query": user_input, "msg": str(e)}

def calculate_relevance_score(result: Dict) -> float:
    """è®¡ç®—ç»¼åˆç›¸å…³æ€§åˆ†æ•°"""
    vector_score = result.get("vector_score", 0)
    rerank_score = result.get("rerank_score", 0)
    
    # å¦‚æœé‡æ’åºåˆ†æ•°å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨é‡æ’åºåˆ†æ•°
    if rerank_score > 0:
        return rerank_score
    else:
        return vector_score

async def enhance_result_content(query: str, result: Dict) -> Dict:
    """ä½¿ç”¨AIæ¨¡å‹ä¼˜åŒ–ç»“æœå†…å®¹"""
    try:
        source_content = result.get("source_content", "")
        if not source_content:
            return result
        
        # æ„å»ºä¼˜åŒ–æç¤º
        enhancement_prompt = f"""
        åŸºäºä»¥ä¸‹æŸ¥è¯¢å’Œæºæ–‡æœ¬ï¼Œç”Ÿæˆä¼˜åŒ–åçš„å†…å®¹ï¼š
        
        æŸ¥è¯¢ï¼š{query}
        æºæ–‡æœ¬ï¼š{source_content[:1000]}  # é™åˆ¶é•¿åº¦
        
        è¯·ç”Ÿæˆï¼š
        1. ç®€æ´æ‘˜è¦ï¼ˆ100å­—å†…ï¼‰
        2. ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§åˆ†æ
        3. å…³é”®ä¿¡æ¯æå–
        
        è¿”å›JSONæ ¼å¼ã€‚
        """
        
        # è¿™é‡Œå¯ä»¥é›†æˆå„ç§AIæ¨¡å‹è¿›è¡Œå†…å®¹ä¼˜åŒ–
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„æ–‡æœ¬å¤„ç†ä½œä¸ºç¤ºä¾‹
        enhanced_content = {
            "summary": f"å…³äº'{query}'çš„ç›¸å…³ä¿¡æ¯æ‘˜è¦",
            "relevance_analysis": "å†…å®¹ä¸æŸ¥è¯¢é«˜åº¦ç›¸å…³",
            "key_points": ["å…³é”®ç‚¹1", "å…³é”®ç‚¹2", "å…³é”®ç‚¹3"]
        }
        
        result["enhanced_content"] = enhanced_content
        return result
        
    except Exception as e:
        logger.warning(f"âš ï¸  å†…å®¹ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}")
        return result

def generate_query_summary(query: str, results: List[Dict]) -> Dict:
    """ç”ŸæˆæŸ¥è¯¢æ‘˜è¦"""
    total_results = len(results)
    avg_relevance = sum(r.get("relevance_score", 0) for r in results) / max(total_results, 1)
    
    return {
        "query": query,
        "total_results": total_results,
        "average_relevance": round(avg_relevance, 4),
        "top_relevance": max((r.get("relevance_score", 0) for r in results), default=0),
        "timestamp": asyncio.get_event_loop().time() if asyncio.get_event_loop().is_running() else 0
    }

# -------------------------- MCPèµ„æºå®šä¹‰ --------------------------
@mcp.resource("config://app-version")
def get_app_version() -> str:
    """è¿”å›åº”ç”¨ç‰ˆæœ¬ä¿¡æ¯"""
    return "ç”Ÿç‰©å…¥ä¾µMongoDBæœåŠ¡å™¨ v1.0.0"

@mcp.resource("config://server-status")
def get_server_status() -> Dict:
    """è¿”å›æœåŠ¡å™¨çŠ¶æ€ä¿¡æ¯"""
    return {
        "status": "running",
        "environment": ENV,
        "mongo_connected": mongo_client is not None,
        "reranker_loaded": reranker_model is not None,
        "timestamp": asyncio.get_event_loop().time() if asyncio.get_event_loop().is_running() else 0
    }

@mcp.resource("data://species/count")
async def get_species_count() -> Dict:
    """è¿”å›æ•°æ®åº“ä¸­ç‰©ç§æ€»æ•°"""
    try:
        if not mongo_col:
            return {"error": "MongoDBè¿æ¥æœªåˆå§‹åŒ–"}
        
        count = await asyncio.get_event_loop().run_in_executor(
            None, lambda: mongo_col.count_documents({})
        )
        return {"total_species": count}
    except Exception as e:
        return {"error": str(e)}

@mcp.resource("data://species/{species_id}")
async def get_species_by_id(species_id: str) -> Dict:
    """æ ¹æ®IDè·å–ç‰¹å®šç‰©ç§ä¿¡æ¯"""
    try:
        if not mongo_col:
            return {"error": "MongoDBè¿æ¥æœªåˆå§‹åŒ–"}
        
        species = await asyncio.get_event_loop().run_in_executor(
            None, lambda: mongo_col.find_one({"_id": species_id}, {"embedding": 0})
        )
        if species:
            return {"status": "found", "data": species}
        else:
            return {"status": "not_found", "species_id": species_id}
    except Exception as e:
        return {"error": str(e)}

@mcp.resource("info://supported-queries")
def get_supported_queries() -> List[str]:
    """è¿”å›æ”¯æŒçš„æŸ¥è¯¢ç±»å‹åˆ—è¡¨"""
    return [
        "ç‰©ç§åŸºæœ¬ä¿¡æ¯æŸ¥è¯¢",
        "å…¥ä¾µè·¯å¾„åˆ†æ", 
        "åˆ†å¸ƒèŒƒå›´æŸ¥è¯¢",
        "é˜²æ²»æªæ–½æŸ¥è¯¢",
        "é£é™©è¯„ä¼°æŸ¥è¯¢"
    ]

# -------------------------- MCPæç¤ºæ¨¡æ¿ --------------------------
@mcp.prompt(name="species_query", description="æŸ¥è¯¢å…¥ä¾µç‰©ç§è¯¦ç»†ä¿¡æ¯")
def species_query_prompt(species_name: str) -> Dict:
    """ç”Ÿæˆç‰©ç§æŸ¥è¯¢æç¤º
    
    Args:
        species_name (str): å…¥ä¾µç‰©ç§åç§°ï¼ˆå¦‚"çº¢ç«èš"ï¼‰
    
    Returns:
        Dict: MCPæ ‡å‡†æç¤ºæ ¼å¼
    """
    return {
        "description": f"æŸ¥è¯¢{species_name}çš„ç”Ÿç‰©å…¥ä¾µè¯¦ç»†ä¿¡æ¯",
        "messages": [
            {
                "role": "user",
                "content": {
                    "type": "text",
                    "text": f"è¯·æŸ¥è¯¢{species_name}ï¼š1.ç”Ÿç‰©å­¦ç‰¹æ€§ï¼›2.å…¥ä¾µå†å²ï¼›3.åˆ†å¸ƒèŒƒå›´ï¼›4.è¯†åˆ«ç‰¹å¾"
                }
            }
        ]
    }

@mcp.prompt(name="control_measures", description="æŸ¥è¯¢å…¥ä¾µç‰©ç§é˜²æ²»æªæ–½")
def control_measures_prompt(species_name: str) -> Dict:
    """ç”Ÿæˆé˜²æ²»æªæ–½æŸ¥è¯¢æç¤º"""
    return {
        "description": f"æŸ¥è¯¢{species_name}çš„é˜²æ²»æªæ–½",
        "messages": [
            {
                "role": "user",
                "content": {
                    "type": "text",
                    "text": f"è¯·æŸ¥è¯¢{species_name}çš„ï¼š1.ç‰©ç†é˜²æ²»ï¼›2.åŒ–å­¦é˜²æ²»ï¼›3.ç”Ÿç‰©é˜²æ²»ï¼›4.ç»¼åˆç­–ç•¥"
                }
            }
        ]
    }

# -------------------------- èµ„æºæ¸…ç† --------------------------
async def cleanup_resources():
    """é‡Šæ”¾å…¨å±€èµ„æº"""
    logger.info("ğŸ›‘ å¼€å§‹é‡Šæ”¾èµ„æº")
    # å…³é—­MongoDBè¿æ¥
    if mongo_client:
        mongo_client.close()
        logger.info("âœ… MongoDBè¿æ¥å·²å…³é—­")
    # å…³é—­aiohttpä¼šè¯
    if aiohttp_session:
        await aiohttp_session.close()
        logger.info("âœ… aiohttpä¼šè¯å·²å…³é—­")

# -------------------------- ä¸»å‡½æ•° --------------------------
if __name__ == "__main__":
    try:
        # éµå¾ªå®˜æ–¹ç¤ºä¾‹çš„ç®€å•å¯åŠ¨æ–¹å¼
        logger.info("ğŸš€ å¯åŠ¨MCPæœåŠ¡å™¨...")
        mcp.run()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼ˆCtrl+Cï¼‰")
    finally:
        # é‡Šæ”¾èµ„æº
        asyncio.run(cleanup_resources())
        logger.info("âœ… æœåŠ¡å·²å®Œå…¨åœæ­¢")
